{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script perfoms the basic process for applying a machine learning\n",
    "algorithm to a dataset using Python libraries.\n",
    "\n",
    "The four steps are:\n",
    "   1. Download a dataset (using pandas)\n",
    "   2. Process the numeric data (using numpy)\n",
    "   3. Train and evaluate learners (using scikit-learn)\n",
    "   4. Plot and compare results (using matplotlib)\n",
    "\n",
    "\n",
    "The data is downloaded from URL, which is defined below. As is normal\n",
    "for machine learning problems, the nature of the source data affects\n",
    "the entire solution. When you change URL to refer to your own data, you\n",
    "will need to review the data processing steps to ensure they remain\n",
    "correct.\n",
    "\n",
    "============\n",
    "Example Data\n",
    "============\n",
    "The example is from http://mldata.org/repository/data/viewslug/stockvalues/\n",
    "It contains stock prices and the values of three indices for each day\n",
    "over a five year period. See the linked page for more details about\n",
    "this data set.\n",
    "\n",
    "This script uses regression learners to predict the stock price for\n",
    "the second half of this period based on the values of the indices. This\n",
    "is a naive approach, and a more robust method would use each prediction\n",
    "as an input for the next, and would predict relative rather than\n",
    "absolute values.\n",
    "'''\n",
    "\n",
    "# Remember to update the script for the new data when you change this URL\n",
    "URL = \"http://mldata.org/repository/data/download/csv/stockvalues/\"\n",
    "\n",
    "# This is the column of the sample data to predict.\n",
    "# Try changing it to other integers between 1 and 155.\n",
    "TARGET_COLUMN = 32\n",
    "\n",
    "# Uncomment this call when using matplotlib to generate images\n",
    "# rather than displaying interactive UI.\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "from pandas import read_table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # [OPTIONAL] Seaborn makes plots nicer\n",
    "    import seaborn\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_data():\n",
    "    '''\n",
    "    Downloads the data for this script into a pandas DataFrame.\n",
    "    '''\n",
    "\n",
    "    # If your data is in an Excel file, install 'xlrd' and use\n",
    "    # pandas.read_excel instead of read_table\n",
    "    #from pandas import read_excel\n",
    "    #frame = read_excel(URL)\n",
    "\n",
    "    # If your data is in a private Azure blob, install 'azure-storage' and use\n",
    "    # BlockBlobService.get_blob_to_path() with read_table() or read_excel()\n",
    "    #from azure.storage.blob import BlockBlobService\n",
    "    #service = BlockBlobService(ACCOUNT_NAME, ACCOUNT_KEY)\n",
    "    #service.get_blob_to_path(container_name, blob_name, 'my_data.csv')\n",
    "    #frame = read_table('my_data.csv', ...\n",
    "\n",
    "    frame = read_table(\n",
    "        URL,\n",
    "        \n",
    "        # Uncomment if the file needs to be decompressed\n",
    "        #compression='gzip',\n",
    "        #compression='bz2',\n",
    "\n",
    "        # Specify the file encoding\n",
    "        # Latin-1 is common for data from US sources\n",
    "        encoding='latin-1',\n",
    "        #encoding='utf-8',  # UTF-8 is also common\n",
    "\n",
    "        # Specify the separator in the data\n",
    "        sep=',',            # comma separated values\n",
    "        #sep='\\t',          # tab separated values\n",
    "        #sep=' ',           # space separated values\n",
    "\n",
    "        # Ignore spaces after the separator\n",
    "        skipinitialspace=True,\n",
    "\n",
    "        # Generate row labels from each row number\n",
    "        index_col=None,\n",
    "        #index_col=0,       # use the first column as row labels\n",
    "        #index_col=-1,      # use the last column as row labels\n",
    "\n",
    "        # Generate column headers row from each column number\n",
    "        header=None,\n",
    "        #header=0,          # use the first line as headers\n",
    "\n",
    "        # Use manual headers and skip the first row in the file\n",
    "        #header=0,\n",
    "        #names=['col1', 'col2', ...],\n",
    "    )\n",
    "\n",
    "    # Return the entire frame\n",
    "    #return frame\n",
    "\n",
    "    # Return a subset of the columns\n",
    "    return frame[[156, 157, 158, TARGET_COLUMN]]\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "\n",
    "def get_features_and_labels(frame):\n",
    "    '''\n",
    "    Transforms and scales the input data and returns numpy arrays for\n",
    "    training and testing inputs and targets.\n",
    "    '''\n",
    "\n",
    "    # Replace missing values with 0.0\n",
    "    # or we can use scikit-learn to calculate missing values below\n",
    "    #frame[frame.isnull()] = 0.0\n",
    "\n",
    "    # Convert values to floats\n",
    "    arr = np.array(frame, dtype=np.float)\n",
    "\n",
    "    # Normalize the entire data set\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "    arr = MinMaxScaler().fit_transform(arr)\n",
    "\n",
    "    # Use the last column as the target value\n",
    "    X, y = arr[:, :-1], arr[:, -1]\n",
    "    # To use the first column instead, change the index value\n",
    "    #X, y = arr[:, 1:], arr[:, 0]\n",
    "    \n",
    "    # Use 50% of the data for training, but we will test against the\n",
    "    # entire set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.5)\n",
    "    X_test, y_test = X, y\n",
    "    \n",
    "    # If values are missing we could impute them from the training data\n",
    "    #from sklearn.preprocessing import Imputer\n",
    "    #imputer = Imputer(strategy='mean')\n",
    "    #imputer.fit(X_train)\n",
    "    #X_train = imputer.transform(X_train)\n",
    "    #X_test = imputer.transform(X_test)\n",
    "    \n",
    "    # Normalize the attribute values to mean=0 and variance=1\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # To scale to a specified range, use MinMaxScaler\n",
    "    #from sklearn.preprocessing import MinMaxScaler\n",
    "    #scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Fit the scaler based on the training data, then apply the same\n",
    "    # scaling to both training and test sets.\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Return the training and test sets\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "\n",
    "def evaluate_learner(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    Run multiple times with different algorithms to get an idea of the\n",
    "    relative performance of each configuration.\n",
    "\n",
    "    Returns a sequence of tuples containing:\n",
    "        (title, expected values, actual values)\n",
    "    for each learner.\n",
    "    '''\n",
    "\n",
    "    # Use a support vector machine for regression\n",
    "    from sklearn.svm import SVR\n",
    "\n",
    "    # Train using a radial basis function\n",
    "    svr = SVR(kernel='rbf', gamma=0.1)\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    r_2 = svr.score(X_test, y_test)\n",
    "    yield 'RBF Model ($R^2={:.3f}$)'.format(r_2), y_test, y_pred\n",
    "\n",
    "    # Train using a linear kernel\n",
    "    svr = SVR(kernel='linear')\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    r_2 = svr.score(X_test, y_test)\n",
    "    yield 'Linear Model ($R^2={:.3f}$)'.format(r_2), y_test, y_pred\n",
    "\n",
    "    # Train using a polynomial kernel\n",
    "    svr = SVR(kernel='poly', degree=2)\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    r_2 = svr.score(X_test, y_test)\n",
    "    yield 'Polynomial Model ($R^2={:.3f}$)'.format(r_2), y_test, y_pred\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "\n",
    "def plot(results):\n",
    "    '''\n",
    "    Create a plot comparing multiple learners.\n",
    "\n",
    "    `results` is a list of tuples containing:\n",
    "        (title, expected values, actual values)\n",
    "    \n",
    "    All the elements in results will be plotted.\n",
    "    '''\n",
    "\n",
    "    # Using subplots to display the results on the same X axis\n",
    "    fig, plts = plt.subplots(nrows=len(results), figsize=(8, 8))\n",
    "    fig.canvas.set_window_title('Predicting data from ' + URL)\n",
    "\n",
    "    # Show each element in the plots returned from plt.subplots()\n",
    "    for subplot, (title, y, y_pred) in zip(plts, results):\n",
    "        # Configure each subplot to have no tick marks\n",
    "        # (these are meaningless for the sample dataset)\n",
    "        subplot.set_xticklabels(())\n",
    "        subplot.set_yticklabels(())\n",
    "\n",
    "        # Label the vertical axis\n",
    "        subplot.set_ylabel('stock price')\n",
    "\n",
    "        # Set the title for the subplot\n",
    "        subplot.set_title(title)\n",
    "\n",
    "        # Plot the actual data and the prediction\n",
    "        subplot.plot(y, 'b', label='actual')\n",
    "        subplot.plot(y_pred, 'r', label='predicted')\n",
    "        \n",
    "        # Shade the area between the predicted and the actual values\n",
    "        subplot.fill_between(\n",
    "            # Generate X values [0, 1, 2, ..., len(y)-2, len(y)-1]\n",
    "            np.arange(0, len(y), 1),\n",
    "            y,\n",
    "            y_pred,\n",
    "            color='r',\n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "        # Mark the extent of the training data\n",
    "        subplot.axvline(len(y) // 2, linestyle='--', color='0', alpha=0.2)\n",
    "\n",
    "        # Include a legend in each subplot\n",
    "        subplot.legend()\n",
    "\n",
    "    # Let matplotlib handle the subplot layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # ==================================\n",
    "    # Display the plot in interactive UI\n",
    "    plt.show()\n",
    "\n",
    "    # To save the plot to an image file, use savefig()\n",
    "    #plt.savefig('plot.png')\n",
    "\n",
    "    # Open the image file with the default image viewer\n",
    "    #import subprocess\n",
    "    #subprocess.Popen('plot.png', shell=True)\n",
    "\n",
    "    # To save the plot to an image in memory, use BytesIO and savefig()\n",
    "    # This can then be written to any stream-like object, such as a\n",
    "    # file or HTTP response.\n",
    "    #from io import BytesIO\n",
    "    #img_stream = BytesIO()\n",
    "    #plt.savefig(img_stream, fmt='png')\n",
    "    #img_bytes = img_stream.getvalue()\n",
    "    #print('Image is {} bytes - {!r}'.format(len(img_bytes), img_bytes[:8] + b'...'))\n",
    "\n",
    "    # Closing the figure allows matplotlib to release the memory used.\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Download the data set from URL\n",
    "    print(\"Downloading data from {}\".format(URL))\n",
    "    frame = download_data()\n",
    "\n",
    "    # Process data into feature and label arrays\n",
    "    print(\"Processing {} samples with {} attributes\".format(len(frame.index), len(frame.columns)))\n",
    "    X_train, X_test, y_train, y_test = get_features_and_labels(frame)\n",
    "\n",
    "    # Evaluate multiple regression learners on the data\n",
    "    print(\"Evaluating regression learners\")\n",
    "    results = list(evaluate_learner(X_train, X_test, y_train, y_test))\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Plotting the results\")\n",
    "    plot(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
