{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "path = \"C:\\\\Users\\\\Marcelo Queirós\\\\Documents\\\\MIEI\\\\Ano 2\\\\Tese\\\\dataset\\\\\" # nao é preciso pq o código já está neste caminho\n",
    "direc = 'informações_empresas\\\\'\n",
    "file_name ='20181019-sp-100.csv'\n",
    "dataset = pd.read_csv(path + direc + file_name, sep = ';', header=0, engine = \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['CIK'])\n",
    "line = pd.DataFrame({\"CIK\": -1}, index=[-1])\n",
    "df = df.append(line, ignore_index=False)\n",
    "df = df.sort_index().reset_index(drop=True)\n",
    "\n",
    "ini = 2008\n",
    "end = 2018\n",
    "\n",
    "for ano in range(ini, end):\n",
    "    df[str(ano)] = 0\n",
    "    \n",
    "p_empresa = path + \"SP100_10K_\"+ str(ini) + \"-\" + str(end) + \"_company\\\\\"\n",
    "folder_company = 'NAME'\n",
    "\n",
    "for i in range(len(dataset['TICKER SYMBOL'])):\n",
    "    if not os.path.exists(p_empresa + dataset[folder_company][i]):\n",
    "        os.makedirs(p_empresa + dataset[folder_company][i])\n",
    "        \n",
    "\n",
    "for ano in range(ini, end):\n",
    "    for qtr in range(1, 5):\n",
    "        mypath = path + \"10-X_C_2006-2018\\\\\" + str(ano) + \"\\\\QTR\" + str(qtr) + \"\\\\\" #nao é caminho completo\n",
    "        onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "        for name_file in onlyfiles:\n",
    "            # 20060117_10QSB_edgar_data_1039757_0001169232-06-000143_1.txt\n",
    "            cik_file = int(name_file.split('_')[4])\n",
    "            for i in range(len(dataset['CIK'])): \n",
    "                if cik_file == dataset['CIK'][i]:\n",
    "                    ten = name_file.split('_')[1]\n",
    "                    if ten == \"10-K\":\n",
    "                        #if not os.path.exists(p_empresa + dataset[folder_company][i] + \"\\\\\"):\n",
    "                            #os.makedirs(p_empresa + dataset[folder_company][i] + \"\\\\\")\n",
    "                        copyfile(mypath + name_file, p_empresa + dataset[folder_company][i] + \"\\\\\" + name_file)\n",
    "                        df[str(ano)][0]+=1\n",
    "                        df[str(ano)][i+1]+=1\n",
    "                        \n",
    "df.to_csv('emp.csv', sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "                    else:\n",
    "                        if ten[0] == '1' and ten[1] == '0' and ten[2] == '-' and ten[3] == 'K':\n",
    "                            if not os.path.exists(\"SP100_10K_2009-18_company\\\\\" + dataset[folder_company][i] + \"\\\\other\"):\n",
    "                                os.makedirs(\"SP100_10K_2009-18_company\\\\\" + dataset[folder_company][i] + \"\\\\other\")\n",
    "                            copyfile(mypath + name_file, path + \"\\\\SP100_10K_2009-18_company\\\\\" + dataset[folder_company][i] + \"\\\\other\\\\\" + name_file)\n",
    "\n",
    "                        if ten[0] == '1' and ten[1] == '0' and ten[2] == 'K':\n",
    "                            if not os.path.exists(\"SP100_10K_2009-18_company\\\\\" + dataset[folder_company][i] + \"\\\\other\"):\n",
    "                                os.makedirs(\"SP100_10K_2009-18_company\\\\\" + dataset[folder_company][i] + \"\\\\other\")\n",
    "                            copyfile(mypath + name_file, path + \"\\\\SP100_10K_2009-18_company\\\\\" + dataset[folder_company][i] + \"\\\\other\\\\\" + name_file) \n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contadorSB=0\n",
    "\n",
    "df = pd.DataFrame(dataset['CIK'])\n",
    "line = pd.DataFrame({\"CIK\": -1}, index=[-1])\n",
    "df = df.append(line, ignore_index=False)\n",
    "df = df.sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "for ano in range(2009, 2019):\n",
    "    df[str(ano)] = 0\n",
    "\n",
    "\n",
    "for ano in range(2009, 2019):\n",
    "    for qtr in range(1, 5):\n",
    "        mypath = \"10-X_C_2006-2018\\\\\" + str(ano) + \"\\\\QTR\" + str(qtr) + \"\\\\\" #nao é caminho completo\n",
    "        onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "        for name_file in onlyfiles:\n",
    "            # 20060117_10QSB_edgar_data_1039757_0001169232-06-000143_1.txt\n",
    "            ten = name_file.split('_')[1]\n",
    "            if ten[0] == '1' and ten[1] == '0' and ten[2] == '-' and ten[3] == 'K':\n",
    "                cik_file = int(name_file.split('_')[4])\n",
    "                for i in range(len(dataset['CIK'])):\n",
    "                    if cik_file == dataset['CIK'][i]:\n",
    "                        df[str(ano)][0]+=1\n",
    "                        df[str(ano)][i+1]+=1\n",
    "                        \n",
    "                        \n",
    "            if ten[0] == '1' and ten[1] == '0' and ten[2] == 'K':\n",
    "                cik_file = int(name_file.split('_')[4])\n",
    "                for i in range(len(dataset['CIK'])):\n",
    "                    if cik_file == dataset['CIK'][i]:\n",
    "                        contadorSB+=1\n",
    "                        df[str(ano)][0]+=1\n",
    "                        df[str(ano)][i+1]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contadorSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('out.csv', sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1528930"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "copyfile(src, dst)\n",
    "path = \"C:\\\\Users\\\\Marcelo Queirós\\\\Documents\\MIEI\\\\Ano 2\\\\Tese\\\\dataset\\\\\"\n",
    "file_name = path + '20181019-sp-100.csv'\n",
    "\n",
    "dataset = pd.read_csv(file_name, sep = ',', header=0)\n",
    "dataset\n",
    "'''\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df = df.drop(df.index[0])\n",
    "\n",
    "\n",
    "\n",
    "    df['data'], df['horas'] = df.iloc[:,0].str.split(' ').str\n",
    "\n",
    "\n",
    "    df['day'], df['month'], df['year'] = df.iloc[:,11].str.split('/').str\n",
    "\n",
    "    df['hour'], df['minute'] = df.iloc[:,12].str.split(':').str\n",
    "    #df['day'], df['month'], df['year'] = data\n",
    "\n",
    "    df.drop(df.columns[[0]], axis=1, inplace=True) #eliminar data original\n",
    "    df.drop(df.columns[[10]], axis=1, inplace=True) #eliminar data original\n",
    "    df.drop(df.columns[[10]], axis=1, inplace=True) #eliminar data original\n",
    "    df = df[['day', 'month', 'year', 'hour', 'minute', 'Tca', 'Tsupe', '   Tip', '   Te', 'SR', 'Tsupi', 'aberturas ventilação', 'persiana', 'HF', '     Ti']]\n",
    "    df.iloc[:,5] = pd.to_numeric(df.iloc[:,5].str.replace(',', '.'))\n",
    "    df.iloc[:,6] = pd.to_numeric(df.iloc[:,6].str.replace(',', '.'))\n",
    "    df.iloc[:,7] = pd.to_numeric(df.iloc[:,7].str.replace(',', '.'))\n",
    "    df.iloc[:,8] = pd.to_numeric(df.iloc[:,8].str.replace(',', '.'))\n",
    "    df.iloc[:,9] = pd.to_numeric(df.iloc[:,9].str.replace(',', '.'))\n",
    "    df.iloc[:,10] = pd.to_numeric(df.iloc[:,10].str.replace(',', '.'))\n",
    "    df.iloc[:,11] = pd.to_numeric(df.iloc[:,11].str.replace(',', '.'))\n",
    "    df.iloc[:,12] = pd.to_numeric(df.iloc[:,12].replace(',', '.'))\n",
    "    df.iloc[:,13] = pd.to_numeric(df.iloc[:,13].str.replace(',', '.'))\n",
    "    df.iloc[:,14] = pd.to_numeric(df.iloc[:,14].str.replace(',', '.'))\n",
    "    df\n",
    "\n",
    "        #df = df[:-1] #eliminar a ultima linha porque é uma frase informativa\n",
    "\n",
    "        #vamos passar ano e mes para para strings para não ser interpretado como valores\n",
    "\n",
    "        #look_up = {'1': 'First', '2': 'Second', '3': 'Third'}\n",
    "        #df['year'] = df['year'].apply(lambda x: look_up[x])\n",
    "\n",
    "        #look_up = {'01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr', '05': 'May',\n",
    "                   # '06': 'Jun', '07': 'Jul', '08': 'Aug', '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'}\n",
    "\n",
    "        #df['month'] = df['month'].apply(lambda x: look_up[x])\n",
    "\n",
    "        #df = df[['year', 'month', 'pub', 'sales']]\n",
    "    return df\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
